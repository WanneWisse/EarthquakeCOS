{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TFIDF import get_tf_idf_matrix\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import helpers\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = helpers.load_data_exp_1('preprocessed_tweets.csv')\n",
    "vectorised_df = get_tf_idf_matrix(df)\n",
    "\n",
    "original_data = df.copy()\n",
    "subset = vectorised_df.copy().sample(n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'sklearn.cluster._k_means_common._relocate_empty_clusters_sparse'\n",
      "Traceback (most recent call last):\n",
      "  File \"<__array_function__ internals>\", line 177, in where\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Elbow method\n",
    "k_values = range(0, 50)\n",
    "\n",
    "# Calculate the within-cluster sum of squares (WCSS) for each K value\n",
    "wcss = []\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10)\n",
    "    kmeans.fit(subset)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the WCSS values against K values\n",
    "plt.plot(k_values, wcss, 'bx-')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 92422)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\earthquakie\\env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 977 occurrences\n",
      "Label 1: 77 occurrences\n",
      "Label 2: 103 occurrences\n",
      "Label 3: 63 occurrences\n",
      "Label 4: 289 occurrences\n",
      "Label 5: 37 occurrences\n",
      "Label 6: 139 occurrences\n",
      "Label 7: 8 occurrences\n",
      "Label 8: 132 occurrences\n",
      "Label 9: 58 occurrences\n",
      "Label 10: 86 occurrences\n",
      "Label 11: 153 occurrences\n",
      "Label 12: 235 occurrences\n",
      "Label 13: 110 occurrences\n",
      "Label 14: 54 occurrences\n",
      "Label 15: 63 occurrences\n",
      "Label 16: 187 occurrences\n",
      "Label 17: 145 occurrences\n",
      "Label 18: 112 occurrences\n",
      "Label 19: 84 occurrences\n",
      "Label 20: 246 occurrences\n",
      "Label 21: 61 occurrences\n",
      "Label 22: 95 occurrences\n",
      "Label 23: 89 occurrences\n",
      "Label 24: 113 occurrences\n",
      "Label 25: 123 occurrences\n",
      "Label 26: 265 occurrences\n",
      "Label 27: 108 occurrences\n",
      "Label 28: 37 occurrences\n",
      "Label 29: 66 occurrences\n",
      "Label 30: 65 occurrences\n",
      "Label 31: 98 occurrences\n",
      "Label 32: 47 occurrences\n",
      "Label 33: 319 occurrences\n",
      "Label 34: 87 occurrences\n",
      "Label 35: 15 occurrences\n",
      "Label 36: 54 occurrences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>0000000000000000000000000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0003</th>\n",
       "      <th>0004</th>\n",
       "      <th>0006</th>\n",
       "      <th>0007</th>\n",
       "      <th>00089</th>\n",
       "      <th>...</th>\n",
       "      <th>ğ˜µğ˜¶</th>\n",
       "      <th>ğ˜¶ğ˜¤</th>\n",
       "      <th>ğ˜¶ğ˜³ğ˜¶ğ˜®ğ˜¶ğ˜®</th>\n",
       "      <th>ğ˜ºğ˜¢ğ˜³ğ˜¢ğ˜­Ä±ğ˜ºÄ±ğ˜®</th>\n",
       "      <th>ğŸğŸ•ğŸ“ğŸğŸ</th>\n",
       "      <th>ğŸ—ğŸğŸğŸ“ğŸ—ğŸ“ğŸğŸğŸ”</th>\n",
       "      <th>ğŸ­ğŸ§</th>\n",
       "      <th>ğŸ­ğŸ±</th>\n",
       "      <th>ğŸ¯ğŸµğŸ­</th>\n",
       "      <th>ğŸ°ğŸ´ğŸ²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20265</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39443</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  0000  0000000000000000000000000  0001  0003  0004  0006  \\\n",
       "20265  0.0  0.0   0.0                        0.0   0.0   0.0   0.0   0.0   \n",
       "10149  0.0  0.0   0.0                        0.0   0.0   0.0   0.0   0.0   \n",
       "46125  0.0  0.0   0.0                        0.0   0.0   0.0   0.0   0.0   \n",
       "39443  0.0  0.0   0.0                        0.0   0.0   0.0   0.0   0.0   \n",
       "1124   0.0  0.0   0.0                        0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "       0007  00089  ...   ğ˜µğ˜¶   ğ˜¶ğ˜¤  ğ˜¶ğ˜³ğ˜¶ğ˜®ğ˜¶ğ˜®  ğ˜ºğ˜¢ğ˜³ğ˜¢ğ˜­Ä±ğ˜ºÄ±ğ˜®  ğŸğŸ•ğŸ“ğŸğŸ  ğŸ—ğŸğŸğŸ“ğŸ—ğŸ“ğŸğŸğŸ”   ğŸ­ğŸ§  \\\n",
       "20265   0.0    0.0  ...  0.0  0.0     0.0        0.0    0.0        0.0  0.0   \n",
       "10149   0.0    0.0  ...  0.0  0.0     0.0        0.0    0.0        0.0  0.0   \n",
       "46125   0.0    0.0  ...  0.0  0.0     0.0        0.0    0.0        0.0  0.0   \n",
       "39443   0.0    0.0  ...  0.0  0.0     0.0        0.0    0.0        0.0  0.0   \n",
       "1124    0.0    0.0  ...  0.0  0.0     0.0        0.0    0.0        0.0  0.0   \n",
       "\n",
       "        ğŸ­ğŸ±  ğŸ¯ğŸµğŸ­  ğŸ°ğŸ´ğŸ²  \n",
       "20265  0.0  0.0  0.0  \n",
       "10149  0.0  0.0  0.0  \n",
       "46125  0.0  0.0  0.0  \n",
       "39443  0.0  0.0  0.0  \n",
       "1124   0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 92422 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(subset.shape)\n",
    "k = 37  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "\n",
    "kmeans.fit(subset)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "# Print the label distribution\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label {label}: {count} occurrences\")\n",
    "\n",
    "\n",
    "subset.loc[:, 'label'] = labels\n",
    "subset_label_2 = subset[subset['label'] == 2]\n",
    "subset_label_1 = subset[subset['label'] == 1]\n",
    "subset_label_0 = subset[subset['label'] == 0]\n",
    "subset_label_2.head(5)\n",
    "subset_label_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_label_3 = original_data[original_data['label'] == 3]\n",
    "subset_label_20 = original_data[original_data['label'] == 20]\n",
    "subset_label_7 = original_data[original_data['label'] == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189626\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from TFIDF import get_tf_idf_matrix\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import helpers\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#load and vectorise data\n",
    "df = helpers.load_data_exp_1('preprocessed_tweets_english.csv')\n",
    "print(len(df))\n",
    "df = df.head(20000)\n",
    "vectorised_df = get_tf_idf_matrix(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\earthquakie\\env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get clusters\n",
    "k = 4  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "kmeans.fit(vectorised_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only unique words per tweet per cluster {1: [\"earthquake\",\"in\",\"syria\",\"earthquake\"]}\n",
    "labels = kmeans.labels_\n",
    "labels_with_tweets = {}\n",
    "for i, label in enumerate(labels):\n",
    "    if label not in labels_with_tweets:\n",
    "        labels_with_tweets[label] = []\n",
    "    content = df.iloc[i][\"content\"]\n",
    "    splitted_content = content.split()\n",
    "    unique_splitted_content = list(set(splitted_content))\n",
    "    labels_with_tweets[label] += unique_splitted_content\n",
    "\n",
    "#get frequency per word per cluster [{\"earthq\": 18, \"syria\":16},{\"earthq\": 12, \"syria\":16}]\n",
    "topic_count_for_topics = []\n",
    "for label, content in labels_with_tweets.items():\n",
    "    word_count_per_label = {}\n",
    "    for word in content:\n",
    "        if word in word_count_per_label:\n",
    "            word_count_per_label[word] += 1\n",
    "        else:\n",
    "            word_count_per_label[word] = 1\n",
    "    word_count_per_label = dict(sorted(word_count_per_label.items(), key=lambda x: x[1],reverse=True))\n",
    "    topic_count_for_topics.append(word_count_per_label)\n",
    "\n",
    "#similar topics accross clusters, when a topic is in top 10 topics of clusters add count for that word for that topic. {\"earthquake\":10,\"syria\":2}, which means that earthquake is in 10 clusters a frequent word.  \n",
    "similar_topic_counts = {}\n",
    "for topic_count_per_topic in topic_count_for_topics:\n",
    "    for topic, topic_count in list(topic_count_per_topic.items())[0:10]:\n",
    "        if topic not in similar_topic_counts:\n",
    "            similar_topic_counts[topic] = 0\n",
    "        similar_topic_counts[topic] +=1\n",
    "similar_topic_counts = dict(sorted(similar_topic_counts.items(), key=lambda x: x[1],reverse=True))    \n",
    "\n",
    "#delete topics from topic_count_for_topics if topic occurs more than 4 times. So there is too much overlap and frequency so this is not a keyword.\n",
    "for topic_count_per_topic in topic_count_for_topics:\n",
    "    copy_dict = topic_count_per_topic.copy()\n",
    "    for topic, topic_count in copy_dict.items():\n",
    "        if topic in similar_topic_counts and similar_topic_counts[topic] >= 4:\n",
    "            del topic_count_per_topic[topic]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'64', 'hit', 'another', 'southern', 'magnitude'}\n",
      "{'label', 'm30', 'm29', 'm31', 'm28'}\n",
      "{'find', 'displayed', 'label', '000', 'info'}\n",
      "{'label', 'turkey', 'pray', 'syria', '000'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import OrderedDict\n",
    "labels = kmeans.labels_\n",
    "vectorised_df[\"label\"] = labels\n",
    "n_key_words = 5\n",
    "\n",
    "for i in range(k):\n",
    "    data_for_cluster = vectorised_df[vectorised_df[\"label\"] == i]\n",
    "    top_n_words_per_tweet = []\n",
    "    for index, row in data_for_cluster.iterrows():\n",
    "        row = row.delete(\"label\")\n",
    "        top_n_tf_idf = row.nlargest(n_key_words)\n",
    "        top_n_words_per_tweet.append(top_n_tf_idf.index)\n",
    "    \n",
    "    key_words = OrderedDict()\n",
    "    for j in range(n_key_words):\n",
    "        ranked_words = {}\n",
    "        for tweet in top_n_words_per_tweet:\n",
    "            for top_word in tweet:\n",
    "                if top_word not in key_words:\n",
    "                    if top_word not in ranked_words:\n",
    "                        ranked_words[top_word] = 0\n",
    "                    ranked_words[top_word] +=1\n",
    "                    break\n",
    "\n",
    "        ranked_words = sorted(ranked_words.items(), key=lambda x: x[1],reverse=True)\n",
    "        #print(ranked_words)\n",
    "        new_key_word = ranked_words[0][0]\n",
    "        key_words[new_key_word] = None\n",
    "    print(key_words)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# for i, label in enumerate(labels):\n",
    "#     if label not in labels_with_tweets:\n",
    "#         labels_with_tweets[label] = []\n",
    "#     content = df.iloc[i][\"content\"]\n",
    "#     splitted_content = content.split()\n",
    "#     for word in splitted_content:\n",
    "#         tf_idf_score = splitted_content.iloc[i][word]\n",
    "\n",
    "    # unique_splitted_content = list(set(splitted_content))\n",
    "    # labels_with_tweets[label] += unique_splitted_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import numpy as np\n",
    "i=1\n",
    "\n",
    "# Create a new figure\n",
    "fig = plt.figure()\n",
    "\n",
    "for topic_cluster in topic_count_for_topics:\n",
    "    print(1)\n",
    "    ax = fig.add_subplot(5, 2, i)\n",
    "    x = list(topic_cluster.keys())[0:10]\n",
    "    y = [topic_cluster[key] for key in x][0:10]\n",
    "    # creating the bar plot\n",
    "    ax.bar(x, y,\n",
    "            width = 0.4)\n",
    "    ax.set_xticks(x)\n",
    "    #ax.set_xticklabels(y)\n",
    "    i+=1\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
